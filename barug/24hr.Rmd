---
title: "Winning 24-hour Modeling Competitions"
subtitle: "dexgroves.com/talks"
author: "Declan Groves"
date: "13 September 2016"
output: beamer_presentation
---

## But why

 - It's fun!
 - Quick POC
 - Take-home modeling exercises

## Strategy

```
design etl








```

## Strategy

```
design etl
engineer response







```

## Strategy

```
design etl
engineer response
while awake:






```

## Strategy

```
design etl
engineer response
while awake:
    engineer features





```

## Strategy

```
design etl
engineer response
while awake:
    engineer features
    remove features




```

## Strategy

```
design etl
engineer response
while awake:
    engineer features
    remove features
    xgboost



```

## Strategy

```
design etl
engineer response
while awake:
    engineer features
    remove features
    xgboost
    validate actions


```

## Strategy

```
design etl
engineer response
while awake:
    engineer features
    remove features
    xgboost
    validate actions
optimize hyperparameters (maybe go to bed)
```

## Strategy

```
design etl
engineer response
while awake:          ___
    engineer features    |
    remove features      |-- Maximize time spent here
    xgboost              |
    validate actions  ___|
optimize hyperparameters (maybe go to bed)
```

## Response Engineering

> - Transform $y$
> - High performance gain per time investment
> - Example: target a percentage

## Feature Engineering

> - Transform $X$
> - Reverse generative process by thinking
> - ...or just throw stuff at wall

## Example Feature Engineering Targets

\begin{itemize}[<+->]
    \item Dates
    \begin{itemize}
        \item<.-> Example: unix datetime of accident
        \item<.-> Weekend, time-of-day, season, ...
    \end{itemize}
    \item High cardinality factors
    \begin{itemize}
        \item<.-> Example: Make-model-modelyear
        \item<.-> {Another talk}
    \end{itemize}
\end{itemize}

## Feature Pruning

> - Random/unstable predictors do harm
> - Low influence
> - Unexpectedly high influence
> - Counterintuitive trends

## Validation

> - Feedback loops are dangerous
> - Every iteration, credibility is lost

## Validation Hierarchy

  1. Holdout {fits quickly, overfits quickly}
  2. Cross-validation {fits slowly, overfits slowly}
  3. Leaderboard {overfit at your peril}

## Model Speedrunning

\begin{itemize}[<+->]
    \item Sparsity (if it makes sense)
    \item Fewer trees, greater learning rate ($\texttt{eta}$)
    \item Early stopping
    \item Column subsampling
    \begin{itemize}
        \item<.-> $\texttt{colsample\_bytree}$
        \item<.-> $\texttt{colsample\_bylevel}$
    \end{itemize}
\end{itemize}

## Thanks for listening!

  - dexgroves.com/talks
